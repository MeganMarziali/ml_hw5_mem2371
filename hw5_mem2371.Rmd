---
title: "Assignment 5"
author: "Megan Marziali"
date: "Feb 10, 2021"
output:
  word_document: default
editor_options:
  chunk_output_type: console
---

## Part 1: Set-up

### Problem set-up

##### Loading required packages

The following code chunk loads the required packages for the assignment.
```{r packages, message = FALSE}
library(tidyverse) 
library(caret)
library(glmnet)

set.seed(100)
```

##### Loading data into environment and cleaning

```{r data_prepare, message = FALSE, results = FALSE}
alc_data = 
  read.csv("./data/alcohol_use.csv", na = c("", ".", "NA", ".d", ".r")) %>% 
  janitor::clean_names() %>%
  mutate(
    alc_consumption = as.factor(alc_consumption)
  ) %>% 
  select(-x)

summary(alc_data)
```

To clean the data, I stripped off the ID variable and recoded the alcohol consumption variable as a factor. The complete dataset includes 1885 observations. No missing observations are present within the data.

##### Data partitioning

```{r partition, message = FALSE}
train.indices = createDataPartition(y = alc_data$alc_consumption,p = 0.7,list = FALSE)

training = alc_data[train.indices,]
testing = alc_data[-train.indices,]

#Store outcome 
alc_train = training$alc_consumption
alc_test = testing$alc_consumption

#Model.matrix shortcut to removing outcome variable from matrix
x_train = model.matrix(alc_consumption~., training)[,-1]
x_test = model.matrix(alc_consumption~., testing)[,-1]
```

## Problem 1

### 1.1: Choosing alpha and lambda via cross-validation

```{r}
model.1 = train(
  alc_consumption ~., data = training, method = "glmnet",
  trControl = trainControl("cv", number = 10),
 tuneLength = 10
  )

param = model.1$bestTune

# Fitting model
model_1 = glmnet(x_train, alc_train, family = binomial, alpha = param$alpha, lambda = param$lambda)
coef(model_1)
```

### 1.2: Model that uses logistic regression

```{r}
model_2 = glm(alc_consumption ~ . ,family = binomial(link = 'logit'),data = training)
summary(model_2)
```

### 1.3: LASSO model using all features

```{r}
model_3 = cv.glmnet(x_train, alc_train, alpha = 1, standardize = TRUE, family = binomial)

plot(model_3)
model_3$lambda.min
model_3$lambda.1se

model_3_final = glmnet(x_train, alc_train, alpha = 1, lambda = model_3$lambda.1se, family = binomial)
coef(model_3_final)
```

## Part 2: Evaluating Model Performance

### 2.1: Alpha and lambda cross-validation model

```{r}
fitted.results = predict(model_1, x_test, type = 'response') 
fitted.results.p = ifelse(fitted.results > 0.5,1,0)

testing.outcome = (as.numeric(testing$alc_consumption) - 1)

misClasificError = mean(fitted.results.p != testing.outcome, na.rm = T)
print(paste('Accuracy Model 1',1 - misClasificError))
```

The accuracy of model 1 is 0.85.

### 2.2: Evaluating logistic regression model

```{r}
fitted.results.2 = predict(model_2, testing, type = 'response') 
fitted.results.p.2 = ifelse(fitted.results.2 > 0.5,1,0)

testing.outcome.2 = (as.numeric(testing$alc_consumption) - 1)

misClasificError.2 = mean(fitted.results.p.2 != testing.outcome.2, na.rm = T)
print(paste('Accuracy Model 2',1 - misClasificError.2))
```

The accuracy of model 2 is 0.80.

### 2.3: Evaluating LASSO model

```{r}
fitted.results.3 = predict(model_3_final, x_test, type = 'response') 
fitted.results.p.3 = ifelse(fitted.results.3 > 0.5, 1, 0)

testing.outcome.3 = (as.numeric(testing$alc_consumption) - 1)

misClasificError.3 = mean(fitted.results.p.3 != testing.outcome.3, na.rm = T)
print(paste('Accuracy Model 3',1 - misClasificError.3))
```

The accuracy of model 3 is 0.78.

Given the accuracies presented above across models, model 1 would be the best choice as it has the highest accuracy.

## Part 4: Research Questions

This analysis could aid future analyses in multiple ways. Firstly, this analysis outlines an approach for determining predictors of alcohol consumption. This analysis could aid in answering questions regarding variables to intervene on to reduce alcohol consumption, if the research question of interest was to predict variables related to alcohol consumption. Indirectly, this analysis provides insight into a methodological approach to answering the research question. Were someone to want to work with this data, and answer different research questions (i.e. using a different exposure or outcome), they could use this analysis to guide their own in terms of necessary analytic steps. 
