---
title: "Assignment 5"
author: "Megan Marziali"
date: "Feb 10, 2021"
output:
  github_document: default
editor_options:
  chunk_output_type: console
---

## Part 1: Set-up

### Problem set-up

##### Loading required packages

The following code chunk loads the required packages for the assignment.
```{r packages, message = FALSE}
library(tidyverse) 
library(caret)
library(glmnet)

set.seed(100)
```

##### Loading data into environment and cleaning

```{r data_prepare, message = FALSE, results = FALSE}
alc_data = 
  read.csv("./data/alcohol_use.csv", na = c("", ".", "NA", ".d", ".r")) %>% 
  janitor::clean_names() %>%
  mutate(
    alc_consumption = as.factor(alc_consumption)
  ) %>% 
  select(-x)

summary(alc_data)
```

To clean the data, I stripped off the ID variable and recoded the alcohol consumption variable as a factor. The complete dataset includes 1885 observations. No missing observations are present within the data.

##### Data partitioning

```{r partition, message = FALSE}
train.indices = createDataPartition(y = alc_data$alc_consumption,p = 0.7,list = FALSE)

training = alc_data[train.indices,]
testing = alc_data[-train.indices,]

#Store outcome 
alc_train = training$alc_consumption
alc_test = testing$alc_consumption

#Model.matrix shortcut to removing outcome variable from matrix
x_train = model.matrix(alc_consumption~., training)[,-1]
x_test = model.matrix(alc_consumption~., testing)[,-1]
```

## Problem 1

### 1.1: Choosing alpha and lambda via cross-validation

```{r}
model.1 = train(
  alc_consumption ~., data = training, method = "glmnet",
  trControl = trainControl("cv", number = 10),
 tuneLength = 10
  )

#Train control for values of hyperparameters, folds, etc.

#Print the values of alpha and lambda that gave best prediction
param = model.1$bestTune

model.1.train.final = glmnet(x_train, alc_train, alpha = param$alpha, lambda = param$lambda, family = binomial)
coef(model.1.train.final)
```

### 1.2: Model that uses logistic regression

```{r}
model.2 = glm(alc_consumption ~ . ,family = binomial(link = 'logit'),data = training)
summary(model.2)
```

### 1.3: LASSO model using all features

```{r}
model.3 = cv.glmnet(x_train, alc_train, alpha = 1, standardize = TRUE, family = binomial)

plot(model.3, xvar = "lambda", label = TRUE)
plot(model.3, xvar = "dev", label = TRUE)

model.3$beta[,1]
```

## Part 2: Evaluating Model Performance

### 2.1: Alpha and lambda cross-validation model

```{r}
fitted.results = predict(model.1.train.final, testing, type = 'response') 
```

